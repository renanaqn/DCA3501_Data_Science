{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f7abcdd",
   "metadata": {},
   "source": [
    "# **CIÊNCIA DE DADOS** - DCA3501\n",
    "\n",
    "UNIVERSIDADE FEDERAL DO RIO GRANDE DO NORTE, NATAL/RN\n",
    "\n",
    "DEPARTAMENTO DE ENGENHARIA DE COMPUTAÇÃO E AUTOMAÇÃO\n",
    "\n",
    "(C) 2025-2026 CARLOS M D VIEGAS\n",
    "\n",
    "https://github.com/cmdviegas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c288de6",
   "metadata": {},
   "source": [
    "# V. Ingestão de Dados\n",
    "\n",
    "Este notebook demonstra técnicas de **ingestão/aquisição de dados** de diversas fontes de dados, usando apenas **bibliotecas padrão** do Python.\n",
    "\n",
    "Cobrimos:\n",
    "- Arquivos (CSV, JSON, ZIP, XLS)\n",
    "- SQL com sqlite3 e PostgreSQL\n",
    "- APIs REST\n",
    "- Web scraping\n",
    "- Streaming em tempo real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4557c3",
   "metadata": {},
   "source": [
    "\n",
    "## Sumário\n",
    "1. [Preparação \"do ambiente\"](#sec1)\n",
    "2. [Aquisição de dados a partir de arquivos: CSV, JSON, ZIP e Planilhas XLS](#sec2)\n",
    "3. [Aquisição de dados a partir de Banco de dados SQL](#sec3)\n",
    "4. [Aquisição com consulta a APIs REST](#sec4)\n",
    "5. [Aquisição por meio de Web scraping](#sec5)\n",
    "6. [Aquisição via streaming em tempo real](#sec6)\n",
    "7. [Exercícios para fixação](#sec7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541a985f",
   "metadata": {},
   "source": [
    "## 1. Preparação \"do ambiente\"<a id=\"sec1\"></a>\n",
    "\n",
    "Esta preparação do ambiente é opcional. Entretanto, ela é útil para definir a localização padrão (pasta) de salvamento/leitura de arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fb5e3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define/cria uma pasta para salvar arquivos gerados\n",
    "\n",
    "# Importação da biblioteca\n",
    "from pathlib import Path\n",
    "\n",
    "# Definição do caminho\n",
    "BASE = Path(\"C:/Users/renan/OneDrive/Documentos/UFRN/2025_2/Ciência de Dados/DCA3501_Data_Science/notebooks/files\") # caso esteja usando o colab, pode apenas usar /content/\n",
    "\n",
    "# Criação da pasta (incluindo pastas pai, se necessário)\n",
    "BASE.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "400101e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de todas as bibliotecas necessárias para executar o notebook (opcional)\n",
    "import csv\n",
    "import json\n",
    "# !pip install websockets\n",
    "import requests\n",
    "import asyncio\n",
    "import random\n",
    "import websockets\n",
    "import zipfile\n",
    "import uvicorn\n",
    "import psycopg\n",
    "import sqlite3\n",
    "import time\n",
    "import threading\n",
    "from datetime import datetime\n",
    "from io import TextIOWrapper\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from html.parser import HTMLParser\n",
    "from fastapi import FastAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f66494",
   "metadata": {},
   "source": [
    "## 2. Aquisição de dados a partir de arquivos: CSV, JSON, ZIP e Planilhas XLS<a id=\"sec2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e7d129",
   "metadata": {},
   "source": [
    "### 2.1. CSV (Comma-Separated Values)\n",
    "\n",
    "CSV são arquivos de texto com valores separados por vírgula que armazenam dados tabulares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9ebfbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o arquivo CSV (opcional)\n",
    "# Normalmente consideramos que o arquivo já existe, mas aqui criamos um exemplo simples como prova de conceito\n",
    "\n",
    "# Importação de bibliotecas\n",
    "import csv\n",
    "\n",
    "# Nome do arquivo a ser criado\n",
    "csv_path = BASE / \"lista_clientes.csv\"\n",
    "\n",
    "# Dados gerados em uma lista\n",
    "rows = [\n",
    "    {\"id\": 1, \"nome\": \"Ana\",   \"cidade\": \"Natal\",     \"data_cadastro\": \"2024-05-01\"},\n",
    "    {\"id\": 2, \"nome\": \"Bruno\", \"cidade\": \"Recife\",    \"data_cadastro\": \"2024-05-03\"},\n",
    "    {\"id\": 3, \"nome\": \"Carla\", \"cidade\": \"Fortaleza\", \"data_cadastro\": \"2024-06-10\"},\n",
    "    {\"id\": 4, \"nome\": \"Diego\", \"cidade\": \"João Pessoa\",\"data_cadastro\": \"2024-07-02\"}\n",
    "]\n",
    "\n",
    "# Salvamento da lista em arquivo\n",
    "with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=list(rows[0].keys()))\n",
    "    writer.writeheader(); writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "035d0d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1', 'nome': 'Ana', 'cidade': 'Natal', 'data_cadastro': '2024-05-01'}\n",
      "{'id': '2', 'nome': 'Bruno', 'cidade': 'Recife', 'data_cadastro': '2024-05-03'}\n",
      "{'id': '3', 'nome': 'Carla', 'cidade': 'Fortaleza', 'data_cadastro': '2024-06-10'}\n",
      "{'id': '4', 'nome': 'Diego', 'cidade': 'João Pessoa', 'data_cadastro': '2024-07-02'}\n"
     ]
    }
   ],
   "source": [
    "# Aquisição de dados a partir de um arquivo CSV\n",
    "\n",
    "# Importação de bibliotecas\n",
    "import csv\n",
    "\n",
    "# Lendo linha a linha e \"parseando\" datas\n",
    "lidos = []\n",
    "with open(csv_path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        lidos.append(row)\n",
    "\n",
    "# Imprime a saída\n",
    "for row in lidos:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3188af79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 1, Nome: Ana, Cidade: Natal, Data: 2024-05-01 00:00:00\n",
      "ID: 2, Nome: Bruno, Cidade: Recife, Data: 2024-05-03 00:00:00\n",
      "ID: 3, Nome: Carla, Cidade: Fortaleza, Data: 2024-06-10 00:00:00\n",
      "ID: 4, Nome: Diego, Cidade: João Pessoa, Data: 2024-07-02 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Aquisição de dados a partir de um arquivo CSV (com parse de datas)\n",
    "\n",
    "# Importação da biblioteca\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Lendo linha a linha e \"parseando\" datas\n",
    "lidos = []\n",
    "with open(csv_path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            row[\"data_cadastro\"] = datetime.fromisoformat(row[\"data_cadastro\"]) # Converte o formato da data de string pata datetime\n",
    "        except Exception:\n",
    "            pass\n",
    "        lidos.append(row)\n",
    "\n",
    "# Imprime a saída formatada\n",
    "for row in lidos:\n",
    "    print(f\"ID: {row['id']}, Nome: {row['nome']}, Cidade: {row['cidade']}, Data: {row['data_cadastro']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abba4e8",
   "metadata": {},
   "source": [
    "### 2.2. JSON\n",
    "JSON é um formato de texto onde objetos são coleções de pares **{chave: valor}**\n",
    "\n",
    "As chaves são strings e os valores podem ser números, strings, null, outros objetos ou arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f750f9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o arquivo JSON\n",
    "# Normalmente consideramos que o arquivo já existe, mas aqui criamos um exemplo simples como prova de conceito\n",
    "\n",
    "# Importação da biblioteca\n",
    "import json\n",
    "\n",
    "# Nome do arquivo a ser criado\n",
    "json_path = BASE / \"pedidos.json\"\n",
    "\n",
    "# Dados gerados em uma lista\n",
    "pedidos = [\n",
    "    {\"pedido_id\": 101, \"cliente_id\": 1, \"valor\": 123.50, \"itens\": [\"caderno\",\"caneta\"]},\n",
    "    {\"pedido_id\": 102, \"cliente_id\": 2, \"valor\": 55.90,  \"itens\": [\"mouse\"]},\n",
    "    {\"pedido_id\": 103, \"cliente_id\": 1, \"valor\": 310.00, \"itens\": [\"teclado\",\"mouse\",\"hub usb\"]}\n",
    "]\n",
    "\n",
    "# Salvamento da lista em arquivo\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(pedidos, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5946867e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pedido_id': 101, 'cliente_id': 1, 'valor': 123.5, 'itens': ['caderno', 'caneta']}\n",
      "{'pedido_id': 102, 'cliente_id': 2, 'valor': 55.9, 'itens': ['mouse']}\n",
      "{'pedido_id': 103, 'cliente_id': 1, 'valor': 310.0, 'itens': ['teclado', 'mouse', 'hub usb']}\n"
     ]
    }
   ],
   "source": [
    "# Aquisição de dados a partir de um arquivo JSON\n",
    "\n",
    "# Importação da biblioteca\n",
    "import json\n",
    "\n",
    "with open(json_path, encoding=\"utf-8\") as f:\n",
    "    pedidos_lidos = json.load(f)\n",
    "\n",
    "# Imprime a saída\n",
    "for row in pedidos_lidos:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773f1b42",
   "metadata": {},
   "source": [
    "### 2.3. ZIP\n",
    "\n",
    "É um formato de compactação/empacotamento que reduz tamanho e agrupa vários arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42f61c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de um arquivo ZIP contendo o CSV\n",
    "# Normalmente consideramos que o arquivo já existe, mas aqui criamos um exemplo simples como prova de conceito\n",
    "\n",
    "# Importação da biblioteca\n",
    "import zipfile\n",
    "\n",
    "# Se necessário, para instalar a biblioteca:\n",
    "# !pip install zipfile\n",
    "\n",
    "# Definição do nome do arquivo ZIP\n",
    "zip_path = BASE / \"clientes_compactado.zip\"\n",
    "\n",
    "# Criação do arquivo ZIP\n",
    "with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
    "    zf.write(csv_path, arcname=\"clientes.csv\") # Dentro do .zip haverá um arquivo chamado \"clientes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71065260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1', 'nome': 'Ana', 'cidade': 'Natal', 'data_cadastro': '2024-05-01'}\n",
      "{'id': '2', 'nome': 'Bruno', 'cidade': 'Recife', 'data_cadastro': '2024-05-03'}\n",
      "{'id': '3', 'nome': 'Carla', 'cidade': 'Fortaleza', 'data_cadastro': '2024-06-10'}\n",
      "{'id': '4', 'nome': 'Diego', 'cidade': 'João Pessoa', 'data_cadastro': '2024-07-02'}\n"
     ]
    }
   ],
   "source": [
    "# Aquisição de dados a partir de um arquivo ZIP contendo um CSV\n",
    "\n",
    "# Importação da biblioteca\n",
    "from io import TextIOWrapper\n",
    "import zipfile\n",
    "\n",
    "# Leitura do CSV dentro do ZIP\n",
    "z_rows = [] # Cria uma lista vazia\n",
    "with zipfile.ZipFile(zip_path) as zf, zf.open(\"clientes.csv\") as fp:\n",
    "    reader = csv.DictReader(TextIOWrapper(fp, encoding=\"utf-8\")) \n",
    "    # TextIOWrapper converte o stream binário do ZIP em texto (str), já que o csv.DictReader espera strings\n",
    "    for row in reader:\n",
    "        z_rows.append(row)\n",
    "\n",
    "for row in z_rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fecd706",
   "metadata": {},
   "source": [
    "### 2.4. Planilha XLSX (EXCEL)\n",
    "\n",
    "Formato de planilha usado pelo Microsoft Excel para armazenar dados em forma de tabelas, podendo conter células, fórmulas, gráficos, tabelas dinâmicas e macros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1b49de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de um arquivo Excel (XLSX)\n",
    "# Normalmente consideramos que o arquivo já existe, mas aqui criamos um exemplo simples como prova de conceito\n",
    "\n",
    "# IMPORTANTE: Precisa executar a célula que cria o CSV antes, pois depende do dicionário 'rows'\n",
    "\n",
    "# Importação da biblioteca openpyxl para lidar com arquivos .xlsx\n",
    "from openpyxl import Workbook, load_workbook\n",
    "\n",
    "# Se necessário, para instalar a biblioteca:\n",
    "# !pip install openpyxl\n",
    "\n",
    "# Definição do nome do arquivo XLSX\n",
    "xlsx_path = BASE / \"planilha_clientes.xlsx\"\n",
    "\n",
    "wb = Workbook() # Cria um novo arquivo Excel em memória\n",
    "ws = wb.active # Seleciona a planilha ativa (default)\n",
    "ws.title = \"clientes\" # Renomeia a planilha como 'clientes'\n",
    "\n",
    "# Adiciona os dados (os mesmos da variável 'rows' criada anteriormente)\n",
    "ws.append([\"id\",\"nome\",\"cidade\",\"data_cadastro\"])\n",
    "for r in rows:\n",
    "    ws.append([r[\"id\"], r[\"nome\"], r[\"cidade\"], r[\"data_cadastro\"]])\n",
    "\n",
    "# Salva o arquivo\n",
    "wb.save(xlsx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfd1a17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'nome': 'Ana', 'cidade': 'Natal', 'data_cadastro': '2024-05-01'}\n",
      "{'id': 2, 'nome': 'Bruno', 'cidade': 'Recife', 'data_cadastro': '2024-05-03'}\n",
      "{'id': 3, 'nome': 'Carla', 'cidade': 'Fortaleza', 'data_cadastro': '2024-06-10'}\n",
      "{'id': 4, 'nome': 'Diego', 'cidade': 'João Pessoa', 'data_cadastro': '2024-07-02'}\n"
     ]
    }
   ],
   "source": [
    "# Leitura de um arquivo Excel (XLSX)\n",
    "\n",
    "# Importação da biblioteca openpyxl para lidar com arquivos .xlsx\n",
    "from openpyxl import Workbook, load_workbook\n",
    "\n",
    "wb2 = load_workbook(xlsx_path, read_only=True) # Abre o arquivo em modo somente leitura\n",
    "ws2 = wb2[\"clientes\"] # Seleciona a planilha \"clientes\"\n",
    "lidos_excel = [] # Cria uma lista vazia\n",
    "\n",
    "# Lê os dados linha por linha\n",
    "first = True; headers = []\n",
    "for row in ws2.iter_rows(values_only=True):\n",
    "    if first:\n",
    "        headers = list(row); first = False; continue\n",
    "    lidos_excel.append({headers[i]: row[i] for i in range(len(headers))})\n",
    "\n",
    "# Imprime a saída\n",
    "for row in lidos_excel:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d669b5f3",
   "metadata": {},
   "source": [
    "## 3. Aquisição de Dados a partir de Banco de Dados SQL<a id=\"sec3\"></a>\n",
    "\n",
    "### 3.1. SQLite/sqlite3\n",
    "\n",
    "SQLite é um banco de dados SQL embarcado que guarda tudo em um único arquivo. O **sqlite3** é o módulo da biblioteca padrão do Python para conectar e operar um arquivo SQLite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7d165a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação e carga inicial de um banco de dados SQLite\n",
    "# Normalmente consideramos que o arquivo já existe, mas aqui criamos um exemplo simples como prova de conceito\n",
    "\n",
    "# IMPORTANTE: Precisa executar a célula que cria o CSV antes, pois depende do dicionário 'rows'\n",
    "\n",
    "# Importação da biblioteca\n",
    "import sqlite3\n",
    "\n",
    "# Se necessário, para instalar a biblioteca:\n",
    "# !pip install sqlite3\n",
    "\n",
    "# Definição do nome do arquivo de banco de dados\n",
    "db_path = BASE / \"exemplo_vendas.db\"\n",
    "\n",
    "# Criação da conexão e do cursor\n",
    "con = sqlite3.connect(db_path)\n",
    "cur = con.cursor() # Cria o cursor para executar comandos SQL\n",
    "\n",
    "# Criação das tabelas 'clientes' e 'pedidos'\n",
    "cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS clientes (\n",
    " id INTEGER PRIMARY KEY, nome TEXT, cidade TEXT, data_cadastro TEXT)\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS pedidos (\n",
    " pedido_id INTEGER PRIMARY KEY, cliente_id INTEGER, valor REAL, itens TEXT,\n",
    " criado_em TEXT DEFAULT CURRENT_TIMESTAMP,\n",
    " FOREIGN KEY(cliente_id) REFERENCES clientes(id))\"\"\")\n",
    "\n",
    "# Carga de dados inicial (inserção nas tabelas)\n",
    "cur.executemany(\"INSERT OR REPLACE INTO clientes(id,nome,cidade,data_cadastro) VALUES (?,?,?,?)\",\n",
    "                [(r[\"id\"], r[\"nome\"], r[\"cidade\"], r[\"data_cadastro\"]) for r in rows])\n",
    "\n",
    "cur.executemany(\"INSERT OR REPLACE INTO pedidos(pedido_id,cliente_id,valor,itens) VALUES (?,?,?,?)\",\n",
    "                [(p[\"pedido_id\"], p[\"cliente_id\"], p[\"valor\"], json.dumps(p[\"itens\"], ensure_ascii=False)) for p in pedidos])\n",
    "\n",
    "# Confirma as alterações e fecha a conexão\n",
    "con.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15b17d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pedido 101 | Cliente: Ana (Natal) | Valor: 123.50 | Itens: [\"caderno\", \"caneta\"] | Data: 2025-09-09 02:40:23\n",
      "Pedido 102 | Cliente: Bruno (Recife) | Valor: 55.90 | Itens: [\"mouse\"] | Data: 2025-09-09 02:40:23\n",
      "Pedido 103 | Cliente: Ana (Natal) | Valor: 310.00 | Itens: [\"teclado\", \"mouse\", \"hub usb\"] | Data: 2025-09-09 02:40:23\n"
     ]
    }
   ],
   "source": [
    "# Consulta de dados ao banco SQLite\n",
    "\n",
    "# Importação da biblioteca\n",
    "import sqlite3\n",
    "\n",
    "# Consulta paginada (fetchmany) para não estourar memória\n",
    "query = (\"\"\"SELECT p.pedido_id, c.nome, c.cidade, p.valor, p.itens, p.criado_em\n",
    "       FROM pedidos p JOIN clientes c ON c.id = p.cliente_id\n",
    "       ORDER BY p.pedido_id\"\"\")\n",
    "\n",
    "# Define o cursor e executa a consulta\n",
    "cur2 = con.cursor()\n",
    "cur2.execute(query)\n",
    "\n",
    "# Loop para ler e imprimir os resultados em lotes\n",
    "while True:\n",
    "    lote = cur2.fetchmany(2) # Lê 2 registros por vez\n",
    "    if not lote:\n",
    "       break # Sai do loop se não houver mais registros\n",
    "    for row in lote:\n",
    "       print(f\"Pedido {row[0]} | Cliente: {row[1]} ({row[2]}) | \"\n",
    "          f\"Valor: {row[3]:.2f} | Itens: {row[4]} | Data: {row[5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11f848e",
   "metadata": {},
   "source": [
    "### 3.2. PostgreSQL\n",
    "\n",
    "É um sistema de gerenciamento de banco de dados relacional, que segue o padrão SQL e oferece recursos avançados como suporte a transações ACID, procedimentos armazenados, extensões, tipos de dados personalizados, além de funcionalidades de banco de dados objeto-relacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ce9d28d",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "[Errno 11001] getaddrinfo failed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m PG_PASS = \u001b[33m\"\u001b[39m\u001b[33mmypassword\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Conexão com o PostgreSQL\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m conn = \u001b[43mpsycopg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPG_HOST\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPG_PORT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdbname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPG_DB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPG_USER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPG_PASS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Consulta ao banco (aqui assumimos que os dados já existem no banco)\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Tabela: customers (exemplo simples)\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m conn.cursor() \u001b[38;5;28;01mas\u001b[39;00m cur:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\renan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\psycopg\\connection.py:98\u001b[39m, in \u001b[36mConnection.connect\u001b[39m\u001b[34m(cls, conninfo, autocommit, prepare_threshold, context, row_factory, cursor_factory, **kwargs)\u001b[39m\n\u001b[32m     96\u001b[39m timeout = timeout_from_conninfo(params)\n\u001b[32m     97\u001b[39m rv = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m attempts = \u001b[43mconninfo_attempts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m conn_errors: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[e.Error, \u001b[38;5;28mstr\u001b[39m]] = []\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m attempts:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\renan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\psycopg\\_conninfo_attempts.py:53\u001b[39m, in \u001b[36mconninfo_attempts\u001b[39m\u001b[34m(params)\u001b[39m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m last_exc\n\u001b[32m     52\u001b[39m     \u001b[38;5;66;03m# We couldn't resolve anything\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.OperationalError(\u001b[38;5;28mstr\u001b[39m(last_exc))\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m get_param(params, \u001b[33m\"\u001b[39m\u001b[33mload_balance_hosts\u001b[39m\u001b[33m\"\u001b[39m) == \u001b[33m\"\u001b[39m\u001b[33mrandom\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     56\u001b[39m     shuffle(attempts)\n",
      "\u001b[31mOperationalError\u001b[39m: [Errno 11001] getaddrinfo failed"
     ]
    }
   ],
   "source": [
    "# Conexão com PostgreSQL\n",
    "\n",
    "# IMPORTANTE: Neste exemplo, é necessário ter um banco de dados PostgreSQL rodando com as credenciais corretas. \n",
    "\n",
    "# Importação da biblioteca\n",
    "import psycopg\n",
    "\n",
    "# Se necessário, para instalar a biblioteca:\n",
    "# !pip install psycopg[binary]\n",
    "\n",
    "# Conexão com o PostgreSQL \n",
    "# Obs: Ajuste as variáveis de ambiente PG_* conforme necessário\n",
    "PG_HOST = \"postgres-db\"\n",
    "PG_PORT = 5432\n",
    "PG_DB   = \"ecommerce\"\n",
    "PG_USER = \"postgres\"\n",
    "PG_PASS = \"mypassword\"\n",
    "\n",
    "# Conexão com o PostgreSQL\n",
    "conn = psycopg.connect(\n",
    "    host=PG_HOST,\n",
    "    port=PG_PORT,\n",
    "    dbname=PG_DB,\n",
    "    user=PG_USER,\n",
    "    password=PG_PASS,\n",
    ")\n",
    "\n",
    "# Consulta ao banco (aqui assumimos que os dados já existem no banco)\n",
    "# Tabela: customers (exemplo simples)\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT * FROM customers LIMIT 5;\")\n",
    "    rows = cur.fetchall()        # lista de tuplas\n",
    "    cols = [d.name for d in cur.description]\n",
    "print(cols)\n",
    "for r in rows:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684b55bd",
   "metadata": {},
   "source": [
    "## 4. Aquisição com consulta a APIs REST<a id=\"sec4\"></a>\n",
    "\n",
    "Esta seção mostra como obter dados de APIs REST, abordando requisições HTTP. APIs REST são interfaces que permitem a comunicação entre sistemas por meio de requisições HTTP, seguindo princípios simples e padronizados para acessar e manipular dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a381c",
   "metadata": {},
   "source": [
    "### 4.1. FastAPI\n",
    "\n",
    "Neste exemplo vamos utilizar FastAPI, um framework web moderno para Python que facilita criar APIs rápidas e tipadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8322638a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [1236]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://localhost:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     ::1:62995 - \"GET /clientes HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:62997 - \"GET /clientes HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:62999 - \"GET /clientes HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:63000 - \"GET /clientes HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:63002 - \"GET /clientes HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:63004 - \"GET /clientes HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:63005 - \"GET /clientes HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:63007 - \"GET /clientes HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:63009 - \"GET /clientes HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:63010 - \"GET /clientes HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:63012 - \"GET /clientes HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "# Servidor FastAPI que gera dados aleatórios de clientes\n",
    "\n",
    "# Importação das bibliotecas\n",
    "import random\n",
    "import threading\n",
    "from datetime import datetime\n",
    "from fastapi import FastAPI # framework web para APIs\n",
    "import uvicorn # uvicorn é um servidor ASGI = \"asynchronous server gateway interface\"\n",
    "\n",
    "# Se necessário, para instalar a biblioteca:\n",
    "# !pip install fastapi uvicorn\n",
    "\n",
    "# Criação da aplicação FastAPI\n",
    "app = FastAPI()\n",
    "\n",
    "# Endpoint que retorna dados de clientes aleatórios\n",
    "@app.get(\"/clientes\")\n",
    "def get_clientes():\n",
    "    return {\n",
    "        \"id\": random.randint(1, 1000),\n",
    "        \"nome\": random.choice([\"Ana\", \"Bruno\", \"Carla\", \"Diego\"]),\n",
    "        \"cidade\": random.choice([\"Natal\", \"Recife\", \"Fortaleza\", \"João Pessoa\"]),\n",
    "        \"data_cadastro\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "\n",
    "# Função para rodar o servidor em uma thread\n",
    "def run_server():\n",
    "    uvicorn.run(app, host=\"localhost\", port=8000, log_level=\"info\")\n",
    "\n",
    "# Inicia o servidor em background\n",
    "server_thread = threading.Thread(target=run_server, daemon=True)\n",
    "server_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e59927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para forçar o encerramento do servidor (se necessário)\n",
    "# ! lsof -ti:8000 | xargs kill -9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c618277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados:  {'id': 263, 'nome': 'Bruno', 'cidade': 'João Pessoa', 'data_cadastro': '2025-09-08 23:41:08'}\n",
      "Dados:  {'id': 92, 'nome': 'Ana', 'cidade': 'Natal', 'data_cadastro': '2025-09-08 23:41:10'}\n",
      "Dados:  {'id': 930, 'nome': 'Bruno', 'cidade': 'Recife', 'data_cadastro': '2025-09-08 23:41:12'}\n",
      "Dados:  {'id': 441, 'nome': 'Ana', 'cidade': 'João Pessoa', 'data_cadastro': '2025-09-08 23:41:14'}\n",
      "Dados:  {'id': 833, 'nome': 'Bruno', 'cidade': 'Fortaleza', 'data_cadastro': '2025-09-08 23:41:16'}\n",
      "Dados:  {'id': 836, 'nome': 'Bruno', 'cidade': 'Fortaleza', 'data_cadastro': '2025-09-08 23:41:18'}\n",
      "Dados:  {'id': 387, 'nome': 'Carla', 'cidade': 'Recife', 'data_cadastro': '2025-09-08 23:41:20'}\n",
      "Dados:  {'id': 948, 'nome': 'Bruno', 'cidade': 'João Pessoa', 'data_cadastro': '2025-09-08 23:41:22'}\n",
      "Dados:  {'id': 783, 'nome': 'Carla', 'cidade': 'João Pessoa', 'data_cadastro': '2025-09-08 23:41:24'}\n",
      "Dados:  {'id': 659, 'nome': 'Bruno', 'cidade': 'João Pessoa', 'data_cadastro': '2025-09-08 23:41:26'}\n",
      "Dados:  {'id': 694, 'nome': 'Diego', 'cidade': 'Recife', 'data_cadastro': '2025-09-08 23:41:28'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m data = r.json() \u001b[38;5;66;03m# Converte a resposta JSON em dicionário Python\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDados: \u001b[39m\u001b[33m\"\u001b[39m, data) \u001b[38;5;66;03m# Imprime os dados recebidos\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Cliente que consome a API FastAPI\n",
    "\n",
    "# Importação das bibliotecas\n",
    "import requests, time\n",
    "\n",
    "# Configuração do URL da API\n",
    "url = \"http://localhost:8000/clientes\"\n",
    "\n",
    "# Loop infinito para consumir a API a cada 2 segundos\n",
    "while True:\n",
    "    r = requests.get(url) # Faz a requisição GET\n",
    "    data = r.json() # Converte a resposta JSON em dicionário Python\n",
    "    print(\"Dados: \", data) # Imprime os dados recebidos\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa1de70",
   "metadata": {},
   "source": [
    "### 4.2. Outras APIs (abertas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99283eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cep': '59064-900', 'logradouro': 'Avenida Senador Salgado Filho', 'complemento': '2234', 'unidade': 'Natal Shopping Center', 'bairro': 'Candelária', 'localidade': 'Natal', 'uf': 'RN', 'estado': 'Rio Grande do Norte', 'regiao': 'Nordeste', 'ibge': '2408102', 'gia': '', 'ddd': '84', 'siafi': '1761'}\n"
     ]
    }
   ],
   "source": [
    "# Consumo de uma API pública (ViaCEP)\n",
    "import requests\n",
    "r = requests.get(\"https://viacep.com.br/ws/59064900/json/\")\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "10005aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 2, 'per_page': 6, 'total': 12, 'total_pages': 2, 'data': [{'id': 7, 'email': 'michael.lawson@reqres.in', 'first_name': 'Michael', 'last_name': 'Lawson', 'avatar': 'https://reqres.in/img/faces/7-image.jpg'}, {'id': 8, 'email': 'lindsay.ferguson@reqres.in', 'first_name': 'Lindsay', 'last_name': 'Ferguson', 'avatar': 'https://reqres.in/img/faces/8-image.jpg'}, {'id': 9, 'email': 'tobias.funke@reqres.in', 'first_name': 'Tobias', 'last_name': 'Funke', 'avatar': 'https://reqres.in/img/faces/9-image.jpg'}, {'id': 10, 'email': 'byron.fields@reqres.in', 'first_name': 'Byron', 'last_name': 'Fields', 'avatar': 'https://reqres.in/img/faces/10-image.jpg'}, {'id': 11, 'email': 'george.edwards@reqres.in', 'first_name': 'George', 'last_name': 'Edwards', 'avatar': 'https://reqres.in/img/faces/11-image.jpg'}, {'id': 12, 'email': 'rachel.howell@reqres.in', 'first_name': 'Rachel', 'last_name': 'Howell', 'avatar': 'https://reqres.in/img/faces/12-image.jpg'}], 'support': {'url': 'https://contentcaddy.io?utm_source=reqres&utm_medium=json&utm_campaign=referral', 'text': 'Tired of writing endless social media content? Let Content Caddy generate it for you.'}}\n"
     ]
    }
   ],
   "source": [
    "# Consumo de uma API pública com query/paginação (ReqRes)\n",
    "# Para obter sucesso, acesse https://reqres.in/signup e copie a chave da API\n",
    "import requests\n",
    "key = {\"x-api-key\": \"reqres-free-v1\"} # Chave da API\n",
    "r = requests.get(\"https://reqres.in/api/users\", headers=key, params={\"page\": 2})\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83d22081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401 {'message': 'Bad credentials', 'documentation_url': 'https://docs.github.com/rest', 'status': '401'}\n"
     ]
    }
   ],
   "source": [
    "# Consumo de uma API pública com token/autenticação (GitHub)\n",
    "import requests\n",
    "hdr = {\"Authorization\": \"Bearer INSERIR_TOKEN_DO_GITHUB_AQUI\"} # ANTEÇÃO: você precisa inserir o token do github\n",
    "r = requests.get(\"https://api.github.com/user\", headers=hdr)\n",
    "print(r.status_code, r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b51e637",
   "metadata": {},
   "source": [
    "## 5. Web scraping (HTML estático)<a id=\"sec5\"></a>\n",
    "\n",
    "Web scraping é o processo automatizado de extrair dados estruturados de páginas da web, lendo o HTML (ou APIs internas) para reutilizar essas informações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c608a512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\renan\\\\OneDrive\\\\Documentos\\\\UFRN\\\\2025_2\\\\Ciência de Dados\\\\DCA3501_Data_Science\\\\notebooks\\\\files\\\\pagina_web.html'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulamos uma página HTML local\n",
    "html_path = BASE / \"pagina_web.html\"\n",
    "html_content = \"\"\"\n",
    "<!doctype html>\n",
    "<html><head><meta charset=\"utf-8\"><title>Loja Demo</title></head>\n",
    "<body>\n",
    "  <h1>Produtos</h1>\n",
    "  <table id=\"tabela\">\n",
    "    <thead><tr><th>Produto</th><th>Preço</th></tr></thead>\n",
    "    <tbody>\n",
    "      <tr><td>Caderno</td><td>R$ 15,90</td></tr>\n",
    "      <tr><td>Caneta</td><td>R$ 3,50</td></tr>\n",
    "      <tr><td>Mouse</td><td>R$ 79,00</td></tr>\n",
    "    </tbody>\n",
    "  </table>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "html_path.write_text(html_content, encoding=\"utf-8\")\n",
    "str(html_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e81bc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Caderno', 'R$ 15,90'], ['Caneta', 'R$ 3,50'], ['Mouse', 'R$ 79,00']]\n"
     ]
    }
   ],
   "source": [
    "# Parser mínimo de tabela HTML para extrair células (<th>/<td>) de uma tabela <table id=\"tabela\">\n",
    "\n",
    "# Importação da biblioteca\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "# Definição do parser\n",
    "class SimpleTableParser(HTMLParser):\n",
    "    def __init__(self, table_id):\n",
    "        super().__init__()\n",
    "        self.table_id = table_id      # id da tabela alvo no HTML\n",
    "        self.capture = False          # estamos dentro da <table id=\"...\"> correta?\n",
    "        self.in_cell = False          # estamos dentro de uma célula <td> ou <th>?\n",
    "        self.rows = []                # todas as linhas extraídas\n",
    "        self.row = []                 # linha corrente (lista de células)\n",
    "        self.buf = []                 # buffer de texto da célula corrente\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        # Se abriu uma <table>, verifica se é a que queremos (id == table_id)\n",
    "        if tag == \"table\" and dict(attrs).get(\"id\") == self.table_id:\n",
    "            self.capture = True\n",
    "        # Dentro da tabela alvo, ao abrir <td> ou <th>, começa a capturar o texto da célula\n",
    "        elif self.capture and tag in (\"td\", \"th\"):\n",
    "            self.in_cell = True\n",
    "            self.buf = []  # zera o buffer para a nova célula\n",
    "\n",
    "    def handle_endtag(self, tag):\n",
    "        # Ao fechar <td> ou <th>, finaliza a célula: junta o texto e adiciona na linha corrente\n",
    "        if self.capture and tag in (\"td\", \"th\"):\n",
    "            self.row.append(\"\".join(self.buf).strip())\n",
    "            self.in_cell = False\n",
    "        # Ao fechar <tr>, se a linha tiver conteúdo, salva em rows e reseta a linha\n",
    "        elif self.capture and tag == \"tr\":\n",
    "            if self.row:\n",
    "                self.rows.append(self.row)\n",
    "            self.row = []\n",
    "        # Ao fechar </table>, para de capturar\n",
    "        elif tag == \"table\" and self.capture:\n",
    "            self.capture = False\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        # Texto encontrado: se estamos dentro de uma célula, acumula no buffer\n",
    "        if self.in_cell:\n",
    "            self.buf.append(data)\n",
    "\n",
    "# Extraindo...\n",
    "p = SimpleTableParser(\"tabela\")                          # Id da tabela no HTML\n",
    "p.feed(html_path.read_text(encoding=\"utf-8\"))            # Faz o parse do arquivo\n",
    "rows = p.rows                                            # Todas as linhas (inclui header)\n",
    "headers, body = rows[0], rows[1:]                        # Separa cabeçalho e corpo\n",
    "\n",
    "print(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823c00cc",
   "metadata": {},
   "source": [
    "## 6. Aquisição via streaming em tempo real<a id=\"sec6\"></a>\n",
    "\n",
    "Existem diversas tecnologias que permitem trabalhar com dados em tempo real, como Kafka, Spark Streaming, WebSockets, entre outros. Nesta seção, vamos utilizar **WebSockets** para ilustrar o conceito.\n",
    "\n",
    "Um WebSocket é um protocolo que permite a comunicação bidirecional e contínua entre cliente e servidor. Com ele, um servidor pode gerar dados em tempo real, enquanto o cliente se conecta e recebe essas informações de forma imediata, sem precisar ficar requisitando a cada instante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0942feae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Servidor rodando em ws://localhost:8765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enviado: {'id': 924, 'nome': 'Carla', 'cidade': 'Natal', 'data_cadastro': '2025-09-08 23:44:00'}\n",
      "Enviado: {'id': 869, 'nome': 'Diego', 'cidade': 'Natal', 'data_cadastro': '2025-09-08 23:44:02'}\n",
      "Enviado: {'id': 635, 'nome': 'Bruno', 'cidade': 'Natal', 'data_cadastro': '2025-09-08 23:44:04'}\n",
      "Enviado: {'id': 581, 'nome': 'Bruno', 'cidade': 'Natal', 'data_cadastro': '2025-09-08 23:44:06'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "connection handler failed\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\renan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\websockets\\asyncio\\server.py\", line 376, in conn_handler\n",
      "    await self.handler(connection)\n",
      "  File \"C:\\Users\\renan\\AppData\\Local\\Temp\\ipykernel_1236\\839818629.py\", line 21, in handler\n",
      "    await websocket.send(json.dumps(msg))\n",
      "  File \"c:\\Users\\renan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\websockets\\asyncio\\connection.py\", line 476, in send\n",
      "    async with self.send_context():\n",
      "               ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\renan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py\", line 214, in __aenter__\n",
      "    return await anext(self.gen)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\renan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\websockets\\asyncio\\connection.py\", line 957, in send_context\n",
      "    raise self.protocol.close_exc from original_exc\n",
      "websockets.exceptions.ConnectionClosedOK: received 1000 (OK); then sent 1000 (OK)\n"
     ]
    }
   ],
   "source": [
    "# Importação das bibliotcas\n",
    "import asyncio\n",
    "import random\n",
    "import websockets\n",
    "from datetime import datetime\n",
    "\n",
    "# Se necessário, para instalar a biblioteca:\n",
    "# !pip install websockets\n",
    "\n",
    "# Função que será executada para cada cliente conectado\n",
    "async def handler(websocket):\n",
    "    while True:\n",
    "        # Gera uma mensagem com dados aleatórios\n",
    "        msg = {\n",
    "            \"id\": random.randint(1, 1000),\n",
    "            \"nome\": random.choice([\"Ana\", \"Bruno\", \"Carla\", \"Diego\"]),\n",
    "            \"cidade\": random.choice([\"Recife\", \"Natal\", \"Fortaleza\", \"João Pessoa\"]),\n",
    "            \"data_cadastro\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        # Envia a mensagem como JSON\n",
    "        await websocket.send(json.dumps(msg))\n",
    "        print(\"Enviado:\", msg)\n",
    "        await asyncio.sleep(2)\n",
    "\n",
    "# Inicia servidor (executar só uma vez)\n",
    "server = await websockets.serve(handler, \"localhost\", 8765)\n",
    "print(\"Servidor rodando em ws://localhost:8765\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69180999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para parar o servidor (opcional)\n",
    "server.close(); await server.wait_closed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4926847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado ao servidor!\n",
      "{'id': 924, 'nome': 'Carla', 'cidade': 'Natal', 'data_cadastro': '2025-09-08 23:44:00'}\n",
      "{'id': 869, 'nome': 'Diego', 'cidade': 'Natal', 'data_cadastro': '2025-09-08 23:44:02'}\n",
      "{'id': 635, 'nome': 'Bruno', 'cidade': 'Natal', 'data_cadastro': '2025-09-08 23:44:04'}\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Executa o cliente\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m listen()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mlisten\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mConectado ao servidor!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# Recebe a mensagem\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     msg = \u001b[38;5;28;01mawait\u001b[39;00m websocket.recv()\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# \"Parseia\" o JSON\u001b[39;00m\n\u001b[32m     17\u001b[39m     data = json.loads(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\renan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\websockets\\asyncio\\connection.py:303\u001b[39m, in \u001b[36mConnection.recv\u001b[39m\u001b[34m(self, decode)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    257\u001b[39m \u001b[33;03mReceive the next message.\u001b[39;00m\n\u001b[32m    258\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    300\u001b[39m \n\u001b[32m    301\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recv_messages.get(decode)\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m:\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\renan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\websockets\\asyncio\\messages.py:159\u001b[39m, in \u001b[36mAssembler.get\u001b[39m\u001b[34m(self, decode)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;66;03m# Locking with get_in_progress prevents concurrent execution\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# until get() fetches a complete message or is canceled.\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# First frame\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     frame = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.frames.get(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.closed)\n\u001b[32m    160\u001b[39m     \u001b[38;5;28mself\u001b[39m.maybe_resume()\n\u001b[32m    161\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m frame.opcode \u001b[38;5;129;01mis\u001b[39;00m OP_TEXT \u001b[38;5;129;01mor\u001b[39;00m frame.opcode \u001b[38;5;129;01mis\u001b[39;00m OP_BINARY\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\renan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\websockets\\asyncio\\messages.py:51\u001b[39m, in \u001b[36mSimpleQueue.get\u001b[39m\u001b[34m(self, block)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28mself\u001b[39m.get_waiter = \u001b[38;5;28mself\u001b[39m.loop.create_future()\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_waiter\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     53\u001b[39m     \u001b[38;5;28mself\u001b[39m.get_waiter.cancel()\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Cliente WebSocket para receber dados em tempo real\n",
    "\n",
    "# Importação das bibliotecas\n",
    "import websockets\n",
    "import json\n",
    "\n",
    "# Função do cliente para receber mensagens\n",
    "async def listen():\n",
    "    uri = \"ws://localhost:8765\"\n",
    "    # Conecta ao servidor\n",
    "    async with websockets.connect(uri) as websocket:\n",
    "        print(\"Conectado ao servidor!\")\n",
    "        while True:\n",
    "            # Recebe a mensagem\n",
    "            msg = await websocket.recv()\n",
    "            # \"Parseia\" o JSON\n",
    "            data = json.loads(msg)\n",
    "            print(f\"{data}\")\n",
    "\n",
    "# Executa o cliente\n",
    "await listen()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25ebd75",
   "metadata": {},
   "source": [
    "## 7. Exercícios para fixação<a id=\"sec7\"></a>\n",
    "\n",
    "A seguir estão exercícios baseados nos exemplos do notebook. Cada exercício inclui um enunciado e um *starter code*. \n",
    "> Dica: execute os exemplos anteriores como referência antes de tentar os exercícios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5fbd20",
   "metadata": {},
   "source": [
    "### Exercício 1 - CSV → JSON (ida e volta)\n",
    "**Tarefa:** Converta um arquivo `.csv` para `.json`. Depois, leia o JSON e mostre apenas os registros de acordo com alguma condição (`if`) definida. Os dados podem ser gerados por vocês.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1c46d527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM CSV:\n",
      "{'id': '1', 'nome': 'Ana', 'cidade': 'Natal', 'data_cadastro': '2024-05-01'}\n",
      "{'id': '2', 'nome': 'Bruno', 'cidade': 'Recife', 'data_cadastro': '2024-05-03'}\n",
      "{'id': '3', 'nome': 'Carla', 'cidade': 'Fortaleza', 'data_cadastro': '2024-06-10'}\n",
      "{'id': '4', 'nome': 'Diego', 'cidade': 'João Pessoa', 'data_cadastro': '2024-07-02'}\n",
      "EM JSON:\n",
      "{'id': '1', 'nome': 'Ana', 'cidade': 'Natal', 'data_cadastro': '2024-05-01'}\n",
      "{'id': '3', 'nome': 'Carla', 'cidade': 'Fortaleza', 'data_cadastro': '2024-06-10'}\n",
      "{'id': '4', 'nome': 'Diego', 'cidade': 'João Pessoa', 'data_cadastro': '2024-07-02'}\n"
     ]
    }
   ],
   "source": [
    "# Espaço para respostas dos Exercícios propostos:\n",
    "csv_file_path = BASE / \"lista_clientes.csv\"\n",
    "json_file_path = BASE / \"lista_clientes_em_json.json\"\n",
    "\n",
    "dados = []\n",
    "# Lendo dados do CSV e colocando num dicionário\n",
    "with open(csv_file_path, mode='r', encoding=\"utf-8\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        dados.append(row)\n",
    "\n",
    "# Imprime a saída\n",
    "print(\"EM CSV:\")\n",
    "for row in dados:\n",
    "    print(row)\n",
    "\n",
    "# Pegando os dados do dicionário e salvando em JSON\n",
    "with open(json_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "\n",
    "    json.dump(dados, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(json_file_path, encoding=\"utf-8\") as f:\n",
    "    dados_json = json.load(f)\n",
    "\n",
    "# Imprime a saída\n",
    "print(\"EM JSON:\")\n",
    "for row in dados_json:\n",
    "    if row['cidade'] != 'Recife':\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e186efbb",
   "metadata": {},
   "source": [
    "\n",
    "### Exercício 2 - SQL → exportar para CSV\n",
    "**Tarefa:** A partir do exemplo SQLite anteriormente apresentado, crie uma nova consulta e exporte o resultado da mesma para `clientes_filtrados.csv`. Em seguida, verifique se os dados foram corretamente carregados no arquivo `.csv`, exibindo o conteúdo do mesmo com o método `print()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a672211b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'nome', 'cidade', 'data_cadastro']\n",
      "['1', 'Ana', 'Natal', '2024-05-01']\n",
      "['3', 'Carla', 'Fortaleza', '2024-06-10']\n",
      "['4', 'Diego', 'João Pessoa', '2024-07-02']\n",
      "\n",
      "Nada contra Recife :)\n"
     ]
    }
   ],
   "source": [
    "# Espaço para respostas dos Exercícios propostos:\n",
    "db_path = BASE / \"exemplo_vendas.db\"\n",
    "csv_filtrado_path = BASE / \"clientes_filtrados.csv\"\n",
    "\n",
    "con = sqlite3.connect(db_path)\n",
    "cur = con.cursor()\n",
    "\n",
    "# Consulta os clientes que não são de Recife\n",
    "cur.execute(\"SELECT id, nome, cidade, data_cadastro FROM clientes WHERE cidade != 'Recife'\")\n",
    "rows = cur.fetchall()\n",
    "cols = [desc[0] for desc in cur.description]\n",
    "\n",
    "# Exporta para CSV\n",
    "with open(csv_filtrado_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(cols)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "# Imprime o conteúdo do CSV gerado\n",
    "with open(csv_filtrado_path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        print(row)\n",
    "\n",
    "print(\"\\nNada contra Recife :)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59865ca0",
   "metadata": {},
   "source": [
    "\n",
    "### Exercício 3 - API REST: usuários e emails\n",
    "**Tarefa:** Consulte `https://jsonplaceholder.typicode.com/users` e exiba `name` e `email`. Em seguida, salve o resultado em `usuarios.json`. Utilize as técnicas anteriormente estudadas, obrigatoriamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f6a3f2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome: Leanne Graham, Email: Sincere@april.biz\n",
      "Nome: Ervin Howell, Email: Shanna@melissa.tv\n",
      "Nome: Clementine Bauch, Email: Nathan@yesenia.net\n",
      "Nome: Patricia Lebsack, Email: Julianne.OConner@kory.org\n",
      "Nome: Chelsey Dietrich, Email: Lucio_Hettinger@annie.ca\n",
      "Nome: Mrs. Dennis Schulist, Email: Karley_Dach@jasper.info\n",
      "Nome: Kurtis Weissnat, Email: Telly.Hoeger@billy.biz\n",
      "Nome: Nicholas Runolfsdottir V, Email: Sherwood@rosamond.me\n",
      "Nome: Glenna Reichert, Email: Chaim_McDermott@dana.io\n",
      "Nome: Clementina DuBuque, Email: Rey.Padberg@karina.biz\n"
     ]
    }
   ],
   "source": [
    "# Espaço para respostas dos Exercícios propostos:\n",
    "\n",
    "# Consulta da API\n",
    "url = \"https://jsonplaceholder.typicode.com/users\"\n",
    "resp = requests.get(url)\n",
    "usuarios = resp.json()\n",
    "\n",
    "# Exibe os dados coletados\n",
    "for u in usuarios:\n",
    "    print(f\"Nome: {u['name']}, Email: {u['email']}\")\n",
    "\n",
    "# Salva apenas nome e email em usuarios.json\n",
    "usuarios_filtrados = [{\"nome\": u[\"name\"], \"email\": u[\"email\"]} for u in usuarios]\n",
    "usuarios_json_path = BASE / \"usuarios.json\"\n",
    "with open(usuarios_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(usuarios_filtrados, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136d0c0b",
   "metadata": {},
   "source": [
    "\n",
    "### Exercício 4 - Web Scraping: títulos e links\n",
    "**Tarefa:** Baixe uma página (ex.: Wikipédia de uma cidade) e extraia:  \n",
    "1) Títulos das seções principais (tag `<h2></h2>`).  \n",
    "2) Todos os links do href de uma âncora (tag `<a href=\"\"></a>`) e salve em `links.txt`.\n",
    "\n",
    "Utilize as técnicas anteriormente estudadas, obrigatoriamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc4e94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Títulos <h2> encontrados:\n",
      "- Conteúdo\n",
      "- História\n",
      "- Integrantes\n",
      "- Discografia\n",
      "- Concertos\n",
      "- Videografia\n",
      "- Prêmios e nomeações\n",
      "- Exclusive designer wallpapers and FR & antimicrobial fabrics for contract and residential settings: https://www.skoposhomes.com/quick-easy-wallpaper-installation-hacks-you-need-now/\n",
      "- Ligações externas\n",
      "\n",
      "Fica aí a curiosidade de que alguém deixou um link errado kkk\n",
      "\n",
      "Os links foram salvos em links.txt, porém está englobando tanto os links internos quanto externos.\n",
      "Então passaremos um filtro para salvar apenas os links simples.\n",
      "\n",
      "Total de links simples salvos em links.txt: 498\n"
     ]
    }
   ],
   "source": [
    "# Espaço para respostas dos Exercícios propostos:\n",
    "\n",
    "# Grupo de K-pop Dreamcatcher na Wikipedia\n",
    "html_path = BASE / \"wiki_dreamcatcher.html\"\n",
    "\n",
    "# Parser para extrair títulos <h2> e links <a href=\"\">\n",
    "class WikiParser(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_h2 = False      # Flag para saber se está dentro de um <h2>\n",
    "        self.h2_titles = []     # Lista para armazenar títulos das seções principais\n",
    "        self.links = []         # Lista para armazenar todos os links encontrados\n",
    "        self.buf = []           # Buffer para acumular texto do <h2>\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        # Se encontrar um <h2>, ativa a flag e zera o buffer\n",
    "        if tag == \"h2\":\n",
    "            self.in_h2 = True\n",
    "            self.buf = []\n",
    "        # Se encontrar um <a>, procura pelo atributo href e salva o link\n",
    "        if tag == \"a\":\n",
    "            for attr in attrs:\n",
    "                if attr[0] == \"href\":\n",
    "                    self.links.append(attr[1])\n",
    "\n",
    "    def handle_endtag(self, tag):\n",
    "        # Ao fechar </h2>, salva o título acumulado no buffer\n",
    "        if tag == \"h2\" and self.in_h2:\n",
    "            title = \"\".join(self.buf).strip()\n",
    "            if title:\n",
    "                self.h2_titles.append(title)\n",
    "            self.in_h2 = False\n",
    "            self.buf = []\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        # Acumula o texto dentro do <h2>\n",
    "        if self.in_h2:\n",
    "            self.buf.append(data)\n",
    "\n",
    "# Leitura do conteúdo HTML do arquivo\n",
    "html_content = html_path.read_text(encoding=\"utf-8\")\n",
    "parser = WikiParser()\n",
    "parser.feed(html_content)  # Faz o parsing do HTML\n",
    "\n",
    "# Exibe os títulos das seções principais encontrados\n",
    "print(\"Títulos <h2> encontrados:\")\n",
    "for t in parser.h2_titles:\n",
    "    print(\"-\", t)\n",
    "\n",
    "print(\"\\nFica aí a curiosidade de que alguém deixou um link errado kkk\")\n",
    "\n",
    "# Salva todos os links encontrados\n",
    "links_path = BASE / \"links.txt\"\n",
    "with open(links_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for link in parser.links:\n",
    "        f.write(link + \"\\n\")\n",
    "\n",
    "print(f\"\\nOs links foram salvos em links.txt, porém está englobando tanto os links internos quanto externos.\")\n",
    "print(\"Então passaremos um filtro para salvar apenas os links simples.\")\n",
    "\n",
    "# Salva apenas links simples em links.txt\n",
    "links_simples = [link for link in parser.links if \"#\" not in link]\n",
    "links_path = BASE / \"links.txt\"\n",
    "with open(links_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for link in links_simples:\n",
    "        f.write(link + \"\\n\")\n",
    "\n",
    "print(f\"\\nTotal de links simples salvos em links.txt: {len(links_simples)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
